{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/\"\n",
    "print(\"Loading dataset from: \" + dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 32\n",
    "img_width = 32\n",
    "batch_size = 500\n",
    "\n",
    "# Load the training data\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  dataset_dir + \"/train\",\n",
    "  seed = 512,\n",
    "  image_size = (img_height, img_width),\n",
    "  batch_size = batch_size)\n",
    "\n",
    "# Load the validation data\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  dataset_dir + \"/test\",\n",
    "  seed = 512,\n",
    "  image_size = (img_height, img_width),\n",
    "  batch_size = batch_size)\n",
    "\n",
    "print(\"Training Classes:\")\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "print(\"Testing Classes:\")\n",
    "class_names = val_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e36bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting the error rate and metrics rate\n",
    "def plot_metrics(history, metric):\n",
    "    plt.plot(history.history[metric], label = metric)\n",
    "    plt.plot(history.history['val_' + metric], label='val_' + metric)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Constant values that will be shared by all the models\n",
    "val_true_classes = np.concatenate([y for x, y in val_ds], axis = 0)  # Get true labels\n",
    "class_names = ['FAKE', 'REAL']\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Transfer Learning model using ResNet50\n",
    "ResNet_base_model = tf.keras.applications.ResNet50(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet', \n",
    "    input_shape = (img_height, img_width, 3),\n",
    "    pooling = 'max'\n",
    ")\n",
    "ResNet_base_model.trainable = True\n",
    "\n",
    "# Create a new model on top of the ResNet50 base\n",
    "inputs = tf.keras.Input(shape = (img_height, img_width, 3))\n",
    "x = ResNet_base_model(inputs, training = False)\n",
    "x = BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001)(x)\n",
    "x = Dense(256, \n",
    "          kernel_regularizer = regularizers.l2(0.01), \n",
    "          activity_regularizer = regularizers.l1(0.01), \n",
    "          bias_regularizer = regularizers.l1(0.01),\n",
    "          activation = 'relu')(x)\n",
    "x = Dropout(rate = .4, seed = 512)(x)       \n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "ResNet_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "ResNet_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adamax(learning_rate = .001),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Summary of the model\n",
    "ResNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31085417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the ResNet model architecture\n",
    "tf.keras.utils.plot_model(ResNet_model, show_shapes = True, to_file = 'ResNet_model.png')\n",
    "Image('ResNet_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Transfer Learning model\n",
    "print(\"Starting training with Transfer Learning using ResNet50...\")\n",
    "ResNet_model_history = ResNet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = 100,\n",
    "    verbose = 1,\n",
    "    callbacks = [early_stopping]\n",
    ")\n",
    "print(\"Transfer Learning training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789907c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "val_loss, val_accuracy, val_precision, val_recall = ResNet_model.evaluate(val_ds)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Val Loss: {val_loss:.4f}\")\n",
    "print(f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Val Precision: {val_precision:.4f}\")\n",
    "print(f\"Val Recall: {val_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error rates and metric rates\n",
    "plot_metrics(ResNet_model_history, 'loss')\n",
    "plot_metrics(ResNet_model_history, 'accuracy')\n",
    "plot_metrics(ResNet_model_history, 'precision')\n",
    "plot_metrics(ResNet_model_history, 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Transfer Learning model using VGG16\n",
    "VGG_base_model = tf.keras.applications.VGG16(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet', \n",
    "    input_shape = (img_height, img_width, 3),\n",
    "    pooling = 'max'\n",
    ")\n",
    "VGG_base_model.trainable = True\n",
    "\n",
    "# Create a new model on top of the VGG16 base\n",
    "inputs = tf.keras.Input(shape = (img_height, img_width, 3))\n",
    "x = VGG_base_model(inputs, training = False)\n",
    "x = BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001)(x)\n",
    "x = Dense(256, \n",
    "          kernel_regularizer = regularizers.l2(0.01), \n",
    "          activity_regularizer = regularizers.l1(0.01), \n",
    "          bias_regularizer = regularizers.l1(0.01),\n",
    "          activation = 'relu')(x)\n",
    "x = Dropout(rate = .4, seed = 512)(x)       \n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "VGG_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Transfer Learning model\n",
    "VGG_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adamax(learning_rate = .001),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Build the Transfer Learning model so we can see a summary\n",
    "VGG_model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
